"""
LDPC matrix pool loading and synchronization helpers.

This module provides matrix management functionality including loading from disk,
checksum verification for Alice-Bob synchronization, and automatic PEG generation
for missing matrices.
"""

from __future__ import annotations

import hashlib
from pathlib import Path
from typing import Dict, Iterable, Optional

import numpy as np
import scipy.sparse as sp

from ehok.core import constants
from ehok.core.data_structures import LDPCMatrixPool
from ehok.core.exceptions import MatrixSynchronizationError
from ehok.utils.logging import get_logger
from ehok.implementations.reconciliation.peg_generator import PEGMatrixGenerator, DegreeDistribution

logger = get_logger("reconciliation.matrix_manager")


class LDPCMatrixManager:
    """
    Manage loading and synchronization of LDPC matrices.

    Parameters
    ----------
    matrix_pool : LDPCMatrixPool
        Loaded matrix pool with checksum metadata.
    """

    def __init__(self, matrix_pool: LDPCMatrixPool) -> None:
        self.matrix_pool = matrix_pool

    @classmethod
    def from_directory(
        cls,
        directory: Path,
        frame_size: int = constants.LDPC_FRAME_SIZE,
        rates: Iterable[float] = constants.LDPC_CODE_RATES,
        autogenerate_if_missing: bool = True,
    ) -> "LDPCMatrixManager":
        """
        Load all matrices for the provided rates from a directory.

        Parameters
        ----------
        directory : Path
            Directory containing npz matrices following LDPC_MATRIX_FILE_PATTERN.
        frame_size : int, optional
            Expected frame size, by default constants.LDPC_FRAME_SIZE.
        rates : Iterable[float], optional
            Rates to load, by default constants.LDPC_CODE_RATES.

        Returns
        -------
        LDPCMatrixManager
            Manager instance with loaded pool and checksum.
        """

        directory = directory.expanduser().resolve()
        logger.info("Loading LDPC matrix pool from: %s", directory)
        
        if not directory.exists():
            logger.error("Matrix directory not found: %s", directory)
            raise FileNotFoundError(f"Matrix directory not found: {directory}")

        matrices: Dict[float, sp.spmatrix] = {}
        sorted_rates = tuple(sorted(rates))
        
        logger.debug("Loading matrices for %d rates: %s", len(sorted_rates), list(sorted_rates))
        
        for idx, rate in enumerate(sorted_rates, 1):
            filename = constants.LDPC_MATRIX_FILE_PATTERN.format(
                frame_size=frame_size, rate=rate
            )
            path = directory / filename
            
            if not path.exists():
                if not autogenerate_if_missing:
                    logger.error("Missing LDPC matrix file for rate %.2f: %s", rate, path)
                    raise FileNotFoundError(f"Missing LDPC matrix for rate {rate:.2f}: {path}")

                logger.warning(
                    "Missing LDPC matrix for rate %.2f. Autogenerating with PEG (frame=%d).", rate, frame_size
                )
                path.parent.mkdir(parents=True, exist_ok=True)
                matrix = cls._autogenerate_matrix(frame_size, rate)
                sp.save_npz(path, matrix)
                logger.info("Autogenerated and saved matrix for rate %.2f to %s", rate, path)
            
            logger.debug("[%d/%d] Loading matrix from %s", idx, len(sorted_rates), path.name)
            matrix = sp.load_npz(path)
            
            if matrix.shape[1] != frame_size:
                logger.error(
                    "Matrix %s has frame size %d, expected %d",
                    path.name, matrix.shape[1], frame_size
                )
                raise ValueError(
                    f"Matrix {path} has frame size {matrix.shape[1]}, expected {frame_size}"
                )
            
            matrices[rate] = matrix.astype(np.uint8)
            logger.info(
                "[%d/%d] Loaded matrix rate=%.2f: shape=%s, nnz=%d, density=%.4f",
                idx,
                len(sorted_rates),
                rate,
                matrix.shape,
                matrix.nnz,
                matrix.nnz / (matrix.shape[0] * matrix.shape[1])
            )

        logger.debug("Computing matrix pool checksum...")
        checksum = cls._compute_checksum(matrices)
        logger.info("Matrix pool checksum: %s", checksum[:16] + "...")
        
        pool = LDPCMatrixPool(
            frame_size=frame_size,
            matrices=matrices,
            rates=np.array(sorted_rates),
            checksum=checksum,
        )
        
        logger.info("Matrix pool loaded successfully: %d matrices", len(matrices))
        return cls(pool)

    @staticmethod
    def _autogenerate_matrix(frame_size: int, rate: float) -> sp.spmatrix:
        """
        Generate a parity-check matrix using PEG for fallback scenarios.

        Parameters
        ----------
        frame_size : int
            Matrix column count (codeword length).
        rate : float
            Target code rate in (0, 1).

        Returns
        -------
        scipy.sparse.spmatrix
            Generated parity-check matrix in CSR format.

        Notes
        -----
        This safeguards tests and simulations from hard failures when matrices
        are missing on disk. Prefers the optimized degree distributions; when a
        rate-specific distribution is missing, reuses the base distribution and
        punctures parity rows deterministically to hit the requested rate.

        Autogeneration is slower than loading pre-computed matrices and should
        be avoided in production by ensuring all matrices are pre-generated.
        """

        dist = constants.LDPC_DEGREE_DISTRIBUTIONS.get(rate)
        use_rate = rate
        if dist is None:
            fallback_rate = constants.LDPC_DEFAULT_RATE
            dist = constants.LDPC_DEGREE_DISTRIBUTIONS[fallback_rate]
            use_rate = fallback_rate
            logger.warning(
                "Using fallback degree distribution from rate %.2f for requested rate %.2f",
                fallback_rate,
                rate,
            )

        lambda_dist = DegreeDistribution(
            degrees=dist["lambda"]["degrees"], probabilities=dist["lambda"]["probabilities"]
        )
        rho_dist = DegreeDistribution(
            degrees=dist["rho"]["degrees"], probabilities=dist["rho"]["probabilities"]
        )

        generator = PEGMatrixGenerator(
            n=frame_size,
            rate=use_rate,
            lambda_dist=lambda_dist,
            rho_dist=rho_dist,
            max_tree_depth=constants.PEG_MAX_TREE_DEPTH,
            seed=constants.PEG_DEFAULT_SEED,
        )
        matrix = generator.generate()

        if use_rate != rate:
            matrix = LDPCMatrixManager._apply_puncturing(
                matrix, target_rate=rate, seed=constants.PEG_DEFAULT_SEED
            )
            logger.info(
                "Applied puncturing to adjust matrix from rate %.2f to target rate %.2f",
                use_rate,
                rate,
            )

        return matrix

    @staticmethod
    def _apply_puncturing(matrix: sp.spmatrix, target_rate: float, seed: int) -> sp.spmatrix:
        """
        Reduce parity constraints to reach a higher effective rate via puncturing.

        Parameters
        ----------
        matrix : sp.spmatrix
            Input parity-check matrix.
        target_rate : float
            Desired code rate after puncturing.
        seed : int
            Random seed for deterministic row selection.

        Returns
        -------
        scipy.sparse.spmatrix
            Punctured matrix with fewer rows (higher rate).

        Raises
        ------
        ValueError
            If target_rate is not in (0, 1) or results in non-positive row count.

        Notes
        -----
        Puncturing removes parity check rows to increase the code rate.
        Rows are randomly selected but deterministically (via seed) for reproducibility.
        """
        if target_rate <= 0 or target_rate >= 1:
            raise ValueError("target_rate must be in (0, 1)")

        matrix_csr = matrix.tocsr(copy=False)
        n = matrix_csr.shape[1]
        target_rows = int(round(n * (1.0 - target_rate)))
        if target_rows <= 0:
            raise ValueError("target_rows must be positive after puncturing")
        if target_rows >= matrix_csr.shape[0]:
            return matrix_csr

        rng = np.random.default_rng(seed)
        keep_rows = np.sort(rng.choice(matrix_csr.shape[0], size=target_rows, replace=False))
        return matrix_csr[keep_rows]

    @staticmethod
    def _compute_checksum(matrices: Dict[float, sp.spmatrix]) -> str:
        """
        Compute SHA-256 checksum of matrix pool for synchronization.

        Parameters
        ----------
        matrices : dict of float to sp.spmatrix
            Dictionary mapping rates to parity-check matrices.

        Returns
        -------
        str
            Hexadecimal SHA-256 digest.

        Notes
        -----
        Checksum includes all matrix data (indices, indptr, data arrays) and rates,
        processed in sorted order for determinism. Both Alice and Bob must use
        identical matrices to successfully reconcile blocks.
        """
        digest = hashlib.sha256()
        for rate in sorted(matrices.keys()):
            matrix = matrices[rate].tocsr()
            digest.update(str(rate).encode())
            digest.update(matrix.indptr.tobytes())
            digest.update(matrix.indices.tobytes())
            if matrix.data is not None:
                digest.update(matrix.data.tobytes())
        return digest.hexdigest()

    def verify_checksum(self, remote_checksum: str) -> None:
        """
        Raise if remote checksum mismatches the local pool.
        
        Parameters
        ----------
        remote_checksum : str
            Checksum received from remote party.
            
        Raises
        ------
        MatrixSynchronizationError
            If checksums do not match.
        """
        logger.debug("Verifying matrix pool checksum...")
        logger.debug("  Local:  %s", self.matrix_pool.checksum[:16] + "...")
        logger.debug("  Remote: %s", remote_checksum[:16] + "...")
        
        if remote_checksum != self.matrix_pool.checksum:
            logger.error("Matrix pool checksum MISMATCH!")
            logger.error("  Local:  %s", self.matrix_pool.checksum)
            logger.error("  Remote: %s", remote_checksum)
            raise MatrixSynchronizationError(self.matrix_pool.checksum, remote_checksum)
        
        logger.info("Matrix pool checksum verified: %s", self.matrix_pool.checksum[:16] + "...")

    def get_matrix(self, rate: float) -> sp.spmatrix:
        """
        Retrieve matrix for a specific rate.

        Parameters
        ----------
        rate : float
            LDPC code rate.

        Returns
        -------
        scipy.sparse.spmatrix
            Parity-check matrix for the requested rate.
        """

        if rate not in self.matrix_pool.matrices:
            raise KeyError(f"Rate {rate} not available in matrix pool")
        return self.matrix_pool.matrices[rate]

    @property
    def checksum(self) -> str:
        """
        Return local checksum for synchronization exchange.

        Returns
        -------
        str
            SHA-256 hexadecimal digest of matrix pool.
        """
        return self.matrix_pool.checksum

    @property
    def rates(self) -> np.ndarray:
        """
        Available rates as sorted numpy array.

        Returns
        -------
        np.ndarray
            Sorted array of available code rates.
        """
        return self.matrix_pool.rates

    @property
    def frame_size(self) -> int:
        """
        Frame size n for all matrices.

        Returns
        -------
        int
            Number of columns (codeword length) in all matrices.
        """
        return self.matrix_pool.frame_size
