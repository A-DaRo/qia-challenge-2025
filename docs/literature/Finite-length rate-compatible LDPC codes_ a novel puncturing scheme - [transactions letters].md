IEEE TRANSACTIONS ON COMMUNICATIONS, VOL. 57, NO. 2, FEBRUARY 2009 297

# Transactions Letters

# Finite-Length Rate-Compatible LDPC Codes: A Novel Puncturing Scheme

Badri N. Vellambi and Faramarz Fekri

**Abstract—In this paper, we study rate-compatible puncturing of finite-length low-density parity-check (LDPC) codes. We present a novel rate-compatible puncturing scheme that is easy to implement. Our scheme uses the idea that the degradation in performance is reduced by selecting a puncturing pattern wherein the punctured bits are far apart from each other in the Tanner graph of the code. Although the puncturing scheme presented is tailored to regular codes, it is also directly applicable to irregular parent ensembles. By simulations, the proposed rate-compatible puncturing scheme is shown to be superior to the existing puncturing methods for both regular and irregular LDPC codes over the binary erasure channel (BEC) and the additive white Gaussian noise (AWGN) Channel.**

**Index Terms—Low-density parity-check codes, finite-length codes, rate-compatible puncturing, decoding neighborhood.**

## I. INTRODUCTION

IN certain time-varying channels where *channel state information* (CSI) is available, using a coding scheme with a fixed (code) rate is not optimal. To maximize throughput in such conditions, it is desirable to employ an error correcting scheme that is flexible in terms of its rate so that one can encode at a higher/lower rate when the channel becomes more/less reliable, respectively. Using several encoder-decoder pairs for achieving this flexibility in rate is, in most cases, undesirable. A practical technique for circumventing the above problem is *rate-compatible puncturing*. Puncturing is a good technique that has been studied extensively for various classes of error-correcting codes (and in specific, convolutional codes) [1], [2]. In puncturing, the number of parity bits that are sent over the channel vary based on the condition of the channel. To send a smaller number of parity bits, a selected subset of the set of parity bits are transmitted. A family of punctured codes derived from a single parent code is said to be *rate-compatible* if puncturing is specifically done to ensure that the Tanner graph of a code of higher rate from the family is a subgraph of the Tanner graph of any code from the family that possesses a smaller rate.

The design and analysis of puncturing schemes for LDPC codes in the asymptotic setting (i.e., as the codelength is made arbitrarily large) have been studied by many authors [3]–[6]. However, the analysis of finite-length codes is much harder than that of its asymptotic counterpart. Some work in the area of puncturing schemes for finite-length LDPC codes can be found in [7], [8]. The issue of puncturing LDPC codes has been considered in [9]–[13] with each work considering a different approach. [13] considers the problem of designing a good rate-compatible ensemble of LDPC codes for a given range of rates. In [11], the authors consider the problem of searching and designing a rate-compatible sequence of codes (using the differential evolution procedure [14]), where each code of the sequence is good at its respective rate. In [12], the authors choose a mother code at a rate that is in-between the range of required rates so that the excessive degradation because of puncturing to high rates is minimized. In their scheme, random puncturing is used to obtain codes of higher rates, whereas lower rates are achieved by extension using a novel progressive edge-growth based scheme [15].

Unlike most other works on puncturing LDPC codes, Ha *et al.* investigate the problem of puncturing a given LDPC mother code [9], [10]. They have shown by simulations that over the *additive white Gaussian noise* (AWGN) channel, the codes constructed by their puncturing scheme are superior to those obtained from random puncturing schemes. Just like in [9], [16], we present a novel criteria for puncturing bits from a specific parent code that results in a good rate-compatible family of LDPC codes. In [16], the authors observe a positive correlation between the probability of successful recovery of a bit and the number of unpunctured nodes in the recovery tree of a node. Therefore, in [16], the authors use a *grouping* algorithm to partition the set of bit nodes into various groups. Within each group, they identify the order for puncturing based on their *sorting* algorithm.

The proposed puncturing scheme is similar to that in [16] but differs from theirs in the following way. It neither uses the information regarding the degree of the survived check nodes, nor does it search for optimal nodes during the grouping algorithm. We can classify our puncturing scheme as a partitioning scheme that divides the set of bit nodes into groups. However, during the selection of nodes at any stage of the proposed puncturing scheme, the order in which the nodes are selected is unimportant. It is only important that we puncture the bits obtained from the first round before we puncture those of the next round. Therefore, another difference in the approach of [16] and that of ours is the lack of a sorting algorithm in our scheme.

Throughout this paper, we will assume the following notations and definitions. By a graph, we mean a simple graph (i.e., a multi-graph with no self-loops and no parallel edges). For a graph $G$, we let $V(G)$, $E(G)$, $\Delta(G)$ to be the set of vertices, the set of edges and the girth (i.e., the least number of edges that form a cycle), respectively. For a graph $G$ and a set $A \subseteq V(G)$, $G[A]$ represents the subgraph of $G$ that is induced by the vertices in $A$ (i.e., the graph with vertex set $A$ and edge set $(A \times A) \cap E(G)$) and $N_G(A)$ denotes the set of all neighbors of $A$ in $G$. For vertices $u, v$ of a graph we define $d(u, v)$ to be the length of the shortest path between $u$ and $v$. Finally, the codes used for simulations in this paper are notated in Table I.

The organization of this paper is as follows. The following section describes the intuition behind our puncturing scheme and then presents the algorithm for the construction of a family of punctured codes from a specific parent LDPC code. In Section III, we present our results of simulations and compare our results with existing results of relevance. Section IV concludes our paper.

## II. PROPOSED PUNCTURING SCHEME

In [16], Ha *et al.* approach puncturing finite-length LDPC codes based on their classification of punctured nodes into $k$ step recoverable nodes, where $k$ is a positive integer. The authors claim that, on the average, the magnitudes of the average log-likelihood ratios (LLRs) for $k$ step recoverable ($k$-SR) nodes decrease with increasing $k$. Based on this claim, they present a greedy algorithm to select the bits to be punctured. We suppose that the main disadvantage with this approach is the greedy selection of bits to be punctured. By this mode of selection, the reliability of nodes that are $(k+1)$-SR are in some sense critically dependent on the reliability of $i$-SR nodes for $i \leq k$. In other words, a non-greedy selection of the same number of nodes may guarantee higher probability of recovery for $k$-SR nodes with higher $k$ than the greedy selection-based scheme, whereas the greedy scheme guarantees higher probability of recovery for $k$-SR nodes with lower $k$. However, the non-greedy selection may result in a better average probability of recovery when the probability of successful recovery of all punctured nodes are taken into consideration.

In this paper, we take a slightly different approach to rate-compatible puncturing. Consider the Tanner graph $G$ of a parent LDPC code $C$. Suppose that the bits of $P \subseteq V(G)$ are punctured. Denote $\delta_P = \min\{d(u, v) : u, v \in P, u \neq v\}$ and $\eta_P(C, l)$ to be the average probability of error for an unpunctured node when the bits are punctured and sent through a channel $C$ after $l > 0$ rounds of the message passing. We call a puncturing pattern $P$ to be $l$-optimal if $P$ satisfies the following.

$$\eta_P(C, l) = \min_{\substack{P' \subseteq V(G) \\ |P'| = |P|}} \eta_{P'}(C, l) \tag{1}$$

The following result relates the concept of $l$-optimality with the minimum distance between the punctured bits over the Tanner graph.

*Lemma 1:* Let $G$ be the Tanner graph of a regular LDPC code $C$ with girth $\Delta(G)$. Let $0 < l < \frac{1}{2} \Delta(G)$ be an integer and let $P \subseteq V(G)$ denote the set of bits to be punctured. Then $\delta_P \geq 2l + 1$ guarantees $l$-optimality of $P$.

*Proof:* Suppose that $\delta_P \geq 2l + 1$. Then one sees that for every punctured bit node $w$, the decoding neighborhood [17] of depth $2l$ is a tree and that all bit nodes in the neighborhood are unpunctured. Also, the decoding neighborhoods of depth $2l$ of any two punctured nodes are graph-isomorphic. Since after $l$ iterations, the probability of error for every node in the graph depends only on the decoding neighborhood of depth $2l$, by symmetry, one concludes that the average probability of error for every punctured node is the same. Finally, one can show that the probability of successful decoding of a bit after $l$ iterations with no unpunctured bit in its decoding neighborhood of depth $2l$ is higher than a node whose decoding neighborhood of depth $2l$ contains other punctured nodes. Using the above fact, one can show that such a puncturing scheme $P$ offers the least probability of decoding failure for every unpunctured node after $l$ iterations, and hence is $l$-optimal. ■

Thus, we see that the condition of $l$-optimality (for $l < \frac{1}{2} \Delta(G)$) is guaranteed if one chooses the punctured bits to be a distance of at least $2l + 2$ away from each other. However, it is not clear as to how the concept of $l$-optimality relates to the universal definition of optimality that is based on average bit-error rate (BER). It should also be noted that finding a sufficient criteria guaranteeing $l$-optimality for $2l > \Delta(G)$ is mathematically intractable, since the decoding neighborhood for iterations $l > \lfloor \frac{\delta_P - 1}{2} \rfloor$ is no longer a tree. Hence finding $l$-optimal puncturing patterns becomes a difficult problem. Albeit being optimal in the sense defined above, $l$-optimal puncturing schemes have several shortcomings. For example, for a regular LDPC code of length $n$ from the $(d_v, d_c)$ ensemble, choosing the set of punctured bits $P$ with $\delta_P > 2l > 2$ and $2l < \Delta(G)$ implies that no more than $\lfloor \frac{n}{(d_v d_c)^{\lfloor l/2 \rfloor}} \rfloor$ bits can be punctured. This poses a serious constraint on the range of achievable rates. Another serious issue with this approach is that of rate-compatibility. It is highly unlikely that there exists a nested family of subsets of bit nodes that are each $l$-optimal or almost $l$-optimal for some positive integer $l$. However, we can design puncturing patterns using the intuition that keeping the punctured bits far from each other ensures that decoding neighborhoods contain more unpunctured bit nodes, thereby guaranteeing a good performance under the message-passing decoder. Presented below (Algorithm 1) is a puncturing method that incorporates loosely the above idea of distance while selecting the bits to be punctured. More specifically, each round of our proposed scheme returns a set of nodes that is 1-optimal.

The algorithm takes in a parity-check matrix of an LDPC code and returns the set of indices to be punctured (INDEX). To compute INDEX, the algorithm proceeds as follows. Initially, the algorithm starts with an empty INDEX. At each time step **3** is executed, the algorithm selects a bit node uniformly at random from the set of available indices (REMAIN) and appends the selected vertex to INDEX. It adds all the neighbors of the check nodes connected to the selected node to NEIBOR and again deletes all elements of NEIBOR from REMAIN. In this way, the algorithm guarantees that bit nodes that will be selected in future steps are at least a distance of four away from previously selected bit nodes. Of course, as the algorithm proceeds REMAIN gets smaller and NEIBOR gets bigger until finally REMAIN becomes empty. At this point, NEIBOR is re-initialized and all those check equations that involve the bit nodes in INDEX are deleted from $H$. Similarly, all bit nodes that do not participate in the remaining equations are also deleted to obtain the smaller matrix $H'$ (and its corresponding Tanner graph $G'$). The algorithm is then re-run with $H'$ as input and the whole process is repeated until $H' = \emptyset$.

---

**Algorithm 1 Puncturing Scheme**
**Require:** Tanner graph $G$ of an $m \times n$ matrix $H$
1: (Initialization) Set INDEX = $\emptyset$, REMAIN = $\{1, \dots, n\}$ and NEIBOR = $\emptyset$.
2: If REMAIN = $\emptyset$ go to **3**, else go to **6**.
3: Find a vertex $v$ uniformly at random from REMAIN.
4: Set INDEX = INDEX $\cup \{v\}$ and NEIBOR = NEIBOR $\cup N_G(N_G(v))$.
5: Set REMAIN = REMAIN \ NEIBOR and go to **2**.
6: (Re-initialization) Set NEIBOR = $\{1, 2, \dots, n\} \setminus$ INDEX.
7: Set $J$ to be the set of check nodes (equations) involving only bit nodes in NEIBOR.
8: Set $G' = G[N_G(J) \cup J]$.
9: Set $H'$ to be the parity check matrix corresponding to $G'$.
10: If $H' \neq \emptyset$, then set $H = H'$, $G = G'$ and go to **1**, else output INDEX and halt.

---

It must be noted here that the algorithm presented above is generic and various modifications can be done to boost its performance depending on the ensemble considered. For example, step **3** may be modified for irregular LDPC codes to select bits based on the degree of the bit instead of a uniformly random selection. However, from our simulations, we find that the improvement, in general, is not drastic and can be left to the choice of the designer. Another important point to be noted is the following. At the first round of selection of the bits to be punctured, step **5** ensures that for each node $v$ in INDEX, there is at least one neighboring check node $c_v$ whose all neighbors excluding $v$ are unpunctured. Therefore, if all the unpunctured neighbors of $c_v$ are known with high accuracy after sufficient iterations of decoding, then one can identify $v$ with reasonable accuracy. In other words, the set of punctured bits constructed by the Puncturing Scheme does not contain a stopping set, and hence, one can expect codes of our scheme to perform better than those of random puncturing at least over the BEC.

Suppose that the Puncturing Scheme is completed after $L$ rounds of bit selection and deletion and at the $i^{th}$ round, the algorithm appends a subset $S_i$ of bit nodes to INDEX. Then, it can be observed that if all the unpunctured nodes of the code are received with high accuracy, then the values of bits in the set $S_i$ will be known with high accuracy after the $(L - i + 1)^{th}$ iteration of message passing and hence, by the notation of [16], these nodes are $(L - i + 1)$-SR although the criteria for selection of these nodes follow an approach different from that in [16]. In [16], the criteria for selection in the grouping algorithm is based on the number of unpunctured nodes in the recovery tree of each node and a search for the optimal node is done at each instant of selection. Here, we perform much less work by simply guaranteeing just 1-optimality at each round of selection. Also, within each group, there is no sanctity in the order by which the nodes are selected. However, the amount of computational work done in the selection has a direct bearing on the limited range of rate-compatibility achievable by the Puncturing Scheme alone. In order to increase the range of rate-compatibility, the Additional Puncturing Scheme given below (Algorithm 2) may be implemented. In this scheme, nodes are selected one at a time from the set of nodes that participate least in the equations that relate punctured bits to unpunctured bits. This ensures that by selection of an additional bit, the reduction in the probability of recovery of previously punctured bits is minimized. Also, care is taken at each step to ensure that stopping sets are not contained in the set generated by appending the newly selected bit node to the set of all previously selected nodes.

---

**Algorithm 2 Additional Puncturing Scheme**
**Require:** Tanner graph $G$ of an $m \times n$ matrix $H$.
1: Generate INDEX and $S_i, i = 1, \dots, L$ using the Puncturing Scheme.
2: Set $I$ to be the set of all rows of $H$ that involve bits nodes from exactly one set $S_j$ for some $0 \leq j \leq L$.
3: Set $B$ to be the set of all those bit nodes $v \in \text{INDEX}^c$ that are involved in the least number of equations represented in the rows $I$ of $H$ and such that no stopping set is contained in INDEX $\cup \{v\}$.
4: If $B = \emptyset$ go to **6**, else go to **5**.
5: Select $b \in B$ at random and set INDEX = INDEX $\cup \{v\}$, $B = B \setminus \{b\}$ and go to **3**.
6: Output INDEX and halt.

---

## III. RESULTS OF SIMULATIONS

In this section, we first present the results of our simulations for the proposed scheme described in Section II over the erasure channel and the AWGN channel. For all ensembles of codes notated in Table I, codes of length 1000 were simulated. It must be mentioned here that the design rates of codes from ensembles C1 and C3 are both 0.5, whereas those from ensembles C2 and C4 are 0.2 and 0.38, respectively. To simulate our proposed rate-compatible scheme, the Puncturing Scheme was simulated in conjunction with the Additional Puncturing Scheme. Since our scheme involves random selection of a subset of vertices, during every run of simulation, we obtain a different subset of indices to be punctured (INDEX). However, for the chosen ensembles and codelengths, we find that the average size of INDEX after completion of the Puncturing Scheme alone for multiple independent runs of the scheme to be 229, 322, 230 and 232 for C1, C2, C3 and C4, respectively. Without employing the Additional Puncturing Scheme, we would only be able to achieve a very limited range of rates. For example, the maximum rate attainable by this scheme for ensemble C1 will be only about $\frac{500}{1000 - 229} \approx 0.65$. For each ensemble, for more that 95% of the runs, the Punctured Scheme terminates after two rounds of selection and graph contraction. Also, approximately 60%, 72%, 63%, and 61% of the bits selected in the first round for codes C1, C2, C3, and C4, respectively. However, using the Additional Puncturing Scheme, we can increase the range of rate-compatibility significantly. For example, we could extend the range of rate-compatibility to 0.885 and 0.87 for ensembles C1 and C3, respectively.

TABLE I
NOTATION FOR THE ENSEMBLES USED IN THIS PAPER.

| Notation | Degree Distributions ($\lambda(x)$, $\rho(x)$) |
| :--- | :--- |
| C1 | ($x^2$, $x^5$) |
| C2 | ($x^3$, $x^4$) |
| C3 | ($0.0796x + 0.6923x^2 + 0.2308x^5, 0.4615x^5 + 0.5385x^6$) |
| C4 | ($0.4706x^2 + 0.2353x^7 + 0.2941x^{29}, 0.7843x^9 + 0.2157x^{10}$) |

[IMAGE: BERs of punctured codes of various rates obtained from a code from ensemble C1 over the BEC. The plot shows $log_{10}$(Bit-Error Rate) vs Probability of Erasure ($\epsilon$) for rates (X,0.550), (Y,0.550), (X,0.600), (Y,0.600), (X,0.635), (Y,0.635), (X,0.750), (Y,0.750), and the Mother Code.]

Fig. 1. BERs of punctured codes of various rates obtained from a code from ensemble C1 over the BEC.

In this following, we summarize the results of simulation for the performance of the punctured codes over BEC and AWGN channels. For the sake of convenience, in the figures that follow, we index codes constructed from our proposed punctured scheme by X and by that from Ha *et al.* [16] by Y. We do not present the graphs for random puncturing for the sake of clarity. For brevity, we do not present the results of simulations for ensembles C2 and C4. However, inferences similar to those made for the ensembles C1 and C3 also hold for ensembles C2 and C4. The bit-error rates of the punctured codes obtained from ensemble C1 and C3 are presented in Figures 1 and 2, respectively. The rates of the punctured codes are presented as the second argument in the legend of the figures. It must be noted certain punctured codes with lower rates employ only the bit nodes that are selected using the Puncturing Scheme, certain codes at higher rates, specifically, those with a rate of 0.75 uses the bits selected from the Additional Puncturing Scheme also.

From the figures, it is clear that punctured codes derived from scheme X perform better than those of scheme Y at all simulated rates. It is interesting to note that under our scheme the difference in erasure probabilities required for a BER of $3 \times 10^{-5}$ for the parent and the daughter codes (generated by using only Puncturing Scheme) is almost identical to the difference in their rates implying that the punctured codes are as good at the lower rate as the parent code is at its rate. It is also interesting to note that the difference between our codes and those from scheme Y become stark when the puncturing fraction is higher therefore showing that codes derived from scheme Y deteriorate more due to puncturing than ours. In fact, our scheme offers an improvement of up to two orders of magnitude at higher SNRs (lower $\epsilon$). However, the substantial benefits in BER gained by using the bits of the Puncturing Scheme, start to diminish when the bits obtained from the Additional Puncturing Scheme are used. This can be understood with the following argument. The set of bits to be punctured (INDEX) that is returned by the Puncturing Scheme is maximal in the sense that there is no equation in the parity-check matrix that solely relates only nodes in NEIBOR=INDEX$^c$. Once this limit is reached, further selection of bits seems to create a critical dependence of the accuracy of the newly punctured bits on that of the bits obtained from the Puncturing Scheme. As a result, the degradation is accelerated from this point on. However, the benefits obtained by the punctured nodes obtained by the Puncturing Scheme is sufficient to guarantee that our scheme remains superior for a greater range of rates including those that are obtained by puncturing the bits obtained from the Additional Puncturing Scheme.

[IMAGE: BERs of punctured codes of various rates obtained from a code from ensemble C3 over the BEC. Similar to Fig 1, showing $log_{10}$(Bit-Error Rate) vs Probability of Erasure ($\epsilon$).]

Fig. 2. BERs of punctured codes of various rates obtained from a code from ensemble C3 over the BEC.

[IMAGE: BERs of punctured codes of various rates obtained from a code from ensemble C1 over the AWGN channel. Plot shows $log_{10}$(Bit-Error Rate) vs SNR (in dB) for different rates of schemes X and Y.]

Fig. 3. BERs of punctured codes of various rates obtained from a code from ensemble C1 over the AWGN channel.

Figures 3 and 4 present the BERs of punctured codes from ensembles C1 and C3 for schemes X and Y over the AWGN channel. As before, we see that at higher rates, punctured codes from scheme X outperform those of scheme Y by about two orders of magnitude. Again, it is noticed that the improvement in performance obtained by using our puncturing scheme starts to diminish when bits from the Additional Puncturing Scheme are punctured. Although omitted due to lack of space, it was observed that our scheme provided about an improvement of about order of magnitude in the word-error rate (WER) in comparison to the scheme in [16].

[IMAGE: BERs of punctured codes of various rates obtained from a code from ensemble C3 over the AWGN channel. Plot shows $log_{10}$(Bit-Error Rate) vs SNR (in dB) for different rates of schemes X and Y.]

Fig. 4. BERs of punctured codes of various rates obtained from a code from ensemble C3 over the AWGN channel.

## IV. CONCLUSION

In this paper, we presented a simple rate-compatible puncturing scheme for finite-length low-density parity-check codes. The proposed scheme is easy to implement and allows room for fine-tuning depending on the parent code to be implemented. By simulations it was seen that, over the BEC, the performance deterioration induced by puncturing is almost equal to the corresponding increase in rate due to puncturing. Also, in comparison to the existing schemes, it was found that our scheme offers an improvement of up to two orders of magnitude at high SNRs over other schemes of relevance.

## REFERENCES

[1] J. Hagenauer, “Rate-compatible punctured convolutional codes (rcpc codes) and their applications,” *IEEE Trans. Commun.*, vol. 36, no. 4, pp. 389–399, Apr. 1988.
[2] F. Babich, G. Montorsi, and F. Vatta, “Design of rate-compatible punctured turbo (RCPT) codes,” in *Proc. IEEE International Conference on Communications (ICC 2002)*, vol. 3, May 2002, pp. 1701–1705.
[3] J. Ha, J. Kim, and S. W. McLaughlin, “Rate-compatible puncturing of low-density parity-check codes,” *IEEE Trans. Inform. Theory*, vol. 50, no. 11, pp. 2824–2836, Nov. 2004.
[4] J. Ha and S. W. McLaughlin, “Optimal puncturing distributions for rate-compatible low-density parity-check codes,” in *Proc. 2003 IEEE International Symposium on Information Theory (ISIT)*, Yokohama, Japan, 2003, pp. 233.
[5] ——, “Optimal puncturing of irregular low-density parity-check codes,” in *Proc. IEEE International Conference on Communications (ICC 2003)*, Anchorage, Alaska, May 2003, pp. 3110–3114.
[6] H. Pishro-Nik and F. Fekri, “Results on punctured low-density parity check codes and improved iterative decoding techniques,” in *Proc. 2004 IEEE Information Theory Workshop*, San Antonio, TX, Oct. 2004, pp. 24–29.
[7] C. Di, D. Proietti, I. E. Telatar, T. Richardson, and R. Urbanke, “Finite-length analysis of low-density parity-check codes on the binary erasure channel,” *IEEE Trans. Inform. Theory*, vol. 48, pp. 1570–1579, June 2002.
[8] T. J. Richardson, M. A. Shokrollahi, and R. L. Urbanke, “Finite-length analysis for various low-density-parity-check ensembles for the binary erasure channel,” in *Proc. 2002 IEEE International Symposium on Information Theory (ISIT)*, Lausanne, Switzerland, June 2002, pp. 1.
[9] J. Ha, J. Kim, and S. W. McLaughlin, “Puncturing for finite length low-density parity-check codes,” in *Proc. 2004 IEEE International Symposium on Information Theory (ISIT)*, Chicago, June 2004, pp. 152.
[10] A. Orlitsky, K. Viswanathan, and J. Zhang, “Stopping set distribution of LDPC code ensembles,” *IEEE Trans. Inform. Theory*, vol. 51, pp. 929–953, Mar. 2005.
[11] D. Bi and L. C. Pérez, “Rate-compatible low-density parity-check codes with rate-compatible degree profiles,” *IEE Electron. Lett.*, vol. 42, no. 1, pp. 41–43, Jan. 2006.
[12] M. R. Yazdani and A. H. Banihashemi, “On construction of rate compatible low-density parity-check codes,” *IEEE Commun. Lett.*, vol. 8, no. 3, pp. 159–161, Mar. 2004.
[13] J. Li and K. R. Narayanan, “Rate-compatible low density parity check codes for capacity-approaching ARQ schemes in packet data communications,” in *Proc. International Conference on Communications, Internet and Information Technology (CIIT)*, US Virgin Islands, pp. 201–206, Nov. 2002.
[14] A. Shokrollahi and R. Storn, “Design of efficient erasure codes with differential evolution,” in *Proc. 2000 IEEE International Symposium on Information Theory (ISIT)*, June 2000, pp. 5.
[15] X.-Y. Hu, E. Eleftheriou, and D.-M. Arnold, “Regular and irregular progressive edge-growth tanner graphs.” *IEEE Trans. Inform. Theory*, vol. 51, no. 1, pp. 386–398, 2005.
[16] J. Ha, J. Kim, D. Klinc, and S. W. McLaughlin, “Rate-compatible punctured low-density parity-check codes with short block lengths,” *IEEE Trans. Inform. Theory*, vol. 52, no. 2, pp. 728–738, Feb. 2006.
[17] T. J. Richardson and R. L. Urbanke, “The capacity of low-density parity-check codes under message-passing decoding,” *IEEE Trans. Inform. Theory*, vol. 47, pp. 599–618, Feb. 2001.